{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yQDp0sXX3qE4",
        "outputId": "0c4aaf27-b90c-42e5-8ca1-35a8b25629c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 353, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (283/283), done.\u001b[K\n",
            "remote: Total 353 (delta 95), reused 168 (delta 56), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (353/353), 9.70 MiB | 16.34 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n",
            "/content/LLaMA-Factory\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mevaluation\u001b[0m/  MANIFEST.in     requirements.txt  \u001b[01;34mtests\u001b[0m/\n",
            "CITATION.cff  \u001b[01;34mexamples\u001b[0m/    pyproject.toml  \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/         LICENSE      README.md       setup.py\n",
            "\u001b[01;34mdocker\u001b[0m/       Makefile     README_zh.md    \u001b[01;34msrc\u001b[0m/\n",
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (4.51.3)\n",
            "Collecting datasets<=3.5.0,>=2.16.0 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate<=1.6.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.5.2)\n",
            "Requirement already satisfied: peft<=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.14.0)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.21.1)\n",
            "Collecting gradio<=5.25.0,>=4.38.0 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.14.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.2.0)\n",
            "Collecting tiktoken (from llamafactory==0.9.3.dev0)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (5.29.4)\n",
            "Collecting uvicorn (from llamafactory==0.9.3.dev0)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fastapi (from llamafactory==0.9.3.dev0)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting sse-starlette (from llamafactory==0.9.3.dev0)\n",
            "  Downloading sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (3.10.0)\n",
            "Collecting fire (from llamafactory==0.9.3.dev0)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (6.0.2)\n",
            "Collecting numpy<2.0.0 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<=2.10.6 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.2.2)\n",
            "Collecting av (from llamafactory==0.9.3.dev0)\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.11.0)\n",
            "Collecting tyro<0.9.0 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.6.0+cu124)\n",
            "Collecting bitsandbytes>=0.39.0 (from llamafactory==0.9.3.dev0)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (4.67.1)\n",
            "Collecting xxhash (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.11.15)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.9.0)\n",
            "Collecting ffmpy (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.10.16)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (11.1.0)\n",
            "Collecting pydub (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.13.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.3.dev0) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->llamafactory==0.9.3.dev0)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->llamafactory==0.9.3.dev0) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->llamafactory==0.9.3.dev0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->llamafactory==0.9.3.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->llamafactory==0.9.3.dev0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->llamafactory==0.9.3.dev0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->llamafactory==0.9.3.dev0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->llamafactory==0.9.3.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->llamafactory==0.9.3.dev0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->llamafactory==0.9.3.dev0) (2024.11.6)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.3.dev0)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.3.dev0) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.3.dev0) (0.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory==0.9.3.dev0) (3.0.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.19.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.0.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.3.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.3.dev0) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (2.18.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.3.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (1.17.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.25.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (0.1.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.25.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.2.1-py3-none-any.whl (10 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llamafactory, fire\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.3.dev0-0.editable-py3-none-any.whl size=26550 sha256=13809e7777309681cf5aede83719d05714d2efdc222cd4c09ec6ac4709a342a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3i3l3p0g/wheels/bd/34/05/1e3cb4b8f20c20631b411dc5157b4b150850c03496fa96c2c4\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=bf5871ac0ed3d80b01a3ebc1ae3df3a5d8168f078875c3b7e5d4ad89c89d8be0\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built llamafactory fire\n",
            "Installing collected packages: pydub, xxhash, uvicorn, tomlkit, shtab, semantic-version, ruff, python-multipart, pydantic-core, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, groovy, fsspec, fire, ffmpy, dill, av, aiofiles, tiktoken, starlette, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, sse-starlette, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio, datasets, bitsandbytes, trl, llamafactory\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.1\n",
            "    Uninstalling pydantic_core-2.33.1:\n",
            "      Successfully uninstalled pydantic_core-2.33.1\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.3\n",
            "    Uninstalling pydantic-2.11.3:\n",
            "      Successfully uninstalled pydantic-2.11.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-24.1.0 av-14.3.0 bitsandbytes-0.45.5 datasets-3.5.0 dill-0.3.8 fastapi-0.115.12 ffmpy-0.5.0 fire-0.7.0 fsspec-2024.12.0 gradio-5.25.0 gradio-client-1.8.0 groovy-0.1.2 llamafactory-0.9.3.dev0 multiprocess-0.70.16 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 shtab-1.7.2 sse-starlette-2.2.1 starlette-0.46.2 tiktoken-0.9.0 tomlkit-0.13.2 trl-0.9.6 tyro-0.8.14 uvicorn-0.34.2 xxhash-3.5.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llamafactory 0.9.3.dev0 requires numpy<2.0.0, but you have numpy 2.0.2 which is incompatible.\n",
            "trl 0.9.6 requires numpy<2.0.0,>=1.18.2, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "%rm -rf LLaMA-Factory\n",
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "%cd LLaMA-Factory\n",
        "%ls\n",
        "\n",
        "!pip install -e .[torch,bitsandbytes]\n",
        "!pip install -q numpy==2.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9K7rHNLd054",
        "outputId": "86f91d5b-cfb6-46cb-a8f9-4227cd6e6bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Qwen2.5-1.5B-Instruct'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Total 31 (delta 0), reused 0 (delta 0), pack-reused 31 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (31/31), 3.60 MiB | 6.59 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZBzDdqc8Lkc",
        "outputId": "1400aa35-2c8e-4ca6-c538-f6a3944d198b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import random\n",
        "import json\n",
        "from tabulate import tabulate\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# /content/drive/MyDrive/Colab Notebooks/fineTune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz2Bv-kBPMuR",
        "outputId": "43cb930f-a896-4005-a8e6-f517a016558c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/fineTune/DISC_LAW\n"
          ]
        }
      ],
      "source": [
        "def read_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "def convert_to_alpaca(data, all_data, ref = False):\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        otp = data[i][\"output\"]\n",
        "\n",
        "        if ref == True:\n",
        "            inp = \"\\t\".join(data[i][\"reference\"]) + data[i][\"input\"] # special case only for Triplet because \"ref\" exist in the \"input\" in Triplet-QA\n",
        "        inp = data[i][\"input\"]\n",
        "\n",
        "        item = {\n",
        "        \"instruction\": inp,\n",
        "        \"input\": \"\",\n",
        "        \"output\": otp\n",
        "    }\n",
        "        all_data.append(item)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# load all data\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/fineTune/DISC_LAW\n",
        "data_p = read_jsonl(\"DISC-Law-SFT-Pair.jsonl\")\n",
        "data_pqa = read_jsonl(\"DISC-Law-SFT-Pair-QA-released.jsonl\")\n",
        "data_t = read_jsonl(\"DISC-Law-SFT-Triplet-released.jsonl\")\n",
        "data_tqa = read_jsonl(\"DISC-Law-SFT-Triplet-QA-released.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO85_Ur-P9XF",
        "outputId": "a19f4dce-bc2b-4213-cbd1-ebe8d8bd9413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "257202 28579\n",
            "/content/LLaMA-Factory/data\n"
          ]
        }
      ],
      "source": [
        "# prepare data\n",
        "all_data = []\n",
        "convert_to_alpaca(data_p, all_data, ref = False)\n",
        "convert_to_alpaca(data_pqa, all_data, ref = False)\n",
        "convert_to_alpaca(data_t, all_data, ref = True)\n",
        "convert_to_alpaca(data_tqa, all_data, ref = False)\n",
        "\n",
        "random.seed(9)\n",
        "random.shuffle(all_data)\n",
        "\n",
        "split_ratio = 0.9\n",
        "split_point = int(len(all_data) * 0.9)\n",
        "train_data = all_data[:split_point]\n",
        "test_data = all_data[split_point:]\n",
        "print(len(train_data),len(test_data))\n",
        "\n",
        "%cd /content/LLaMA-Factory/data/\n",
        "with open(\"law_data.json\", \"w\", encoding = \"utf-8\") as f:\n",
        "    json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "data_info = {\"law_data\":{\n",
        "                \"file_name\": \"law_data.json\"}\n",
        "                }\n",
        "\n",
        "dataset_info_path = Path(\"dataset_info.json\")\n",
        "\n",
        "if dataset_info_path.exists():\n",
        "    with open(dataset_info_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        existing_data = json.load(f)\n",
        "else:\n",
        "    existing_data = {}\n",
        "\n",
        "existing_data.update(data_info)\n",
        "\n",
        "with open(dataset_info_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(existing_data, f, indent=2, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6rwbyFa5LkF",
        "outputId": "fa98d3e5-2fd2-4227-8839-0707f625d621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YIfzFgLsm2kS"
      },
      "outputs": [],
      "source": [
        "# %cd /content/LLaMA-Factory/\n",
        "# !GRADIO_SHARE=1 llamafactory-cli webui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6ap81295trx"
      },
      "source": [
        "## Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "psywJyo75vt6",
        "outputId": "79896657-095b-4c8b-993b-5a3ce05def53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/LLaMA-Factory\n",
            "2025-04-19 11:32:31.380687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745062351.615609    2129 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745062351.675056    2129 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-19 11:32:32.146391: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO|2025-04-19 11:32:45] llamafactory.hparams.parser:388 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.float16\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file vocab.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file merges.txt\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:45,984 >> loading file chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2323] 2025-04-19 11:32:46,339 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 11:32:46,339 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 11:32:46,345 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file vocab.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file merges.txt\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 11:32:46,346 >> loading file chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2323] 2025-04-19 11:32:46,749 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|2025-04-19 11:32:46] llamafactory.data.template:143 >> Add <|im_end|> to stop words.\n",
            "[INFO|2025-04-19 11:32:46] llamafactory.data.loader:143 >> Loading dataset law_data.json...\n",
            "Generating train split: 257202 examples [00:10, 25461.63 examples/s]\n",
            "Converting format of dataset: 100% 12000/12000 [00:01<00:00, 8286.23 examples/s]\n",
            "Running tokenizer on dataset: 100% 12000/12000 [00:22<00:00, 543.47 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 26940, 100382, 110573, 24339, 25067, 99749, 116159, 5122, 21894, 24339, 15946, 107976, 11622, 72881, 9370, 109091, 5122, 9909, 14777, 7552, 100382, 61755, 107915, 3837, 104442, 104852, 100382, 110573, 103963, 20074, 62926, 23031, 102043, 101294, 100631, 109859, 31838, 99661, 100623, 9370, 107765, 100355, 100382, 110573, 100623, 24968, 9909, 40820, 7552, 100382, 110573, 105537, 23384, 3837, 104442, 104210, 32664, 100382, 110573, 104510, 104759, 100631, 100382, 110573, 9370, 109874, 101193, 101063, 99600, 100623, 24968, 9909, 44991, 7552, 100382, 110573, 104510, 104759, 3837, 104442, 30440, 106706, 100382, 61755, 107915, 57218, 100382, 110573, 103963, 20074, 18830, 72064, 105918, 38212, 16744, 115825, 100382, 65577, 24968, 9909, 63703, 7552, 100382, 110573, 103963, 20074, 3837, 104442, 18493, 100382, 110573, 101925, 105899, 3837, 44063, 100382, 110573, 57218, 100382, 61755, 107915, 101650, 29490, 72064, 99793, 9370, 48391, 5373, 112950, 49567, 20074, 24968, 9909, 75108, 7552, 100382, 110573, 48927, 20074, 3837, 104442, 100751, 48927, 100382, 110573, 105918, 3837, 100630, 46100, 5373, 39426, 99738, 5373, 107018, 100631, 34317, 103080, 49567, 8997, 26940, 100382, 110573, 24339, 25067, 99749, 117790, 5122, 104439, 100631, 104439, 106320, 99667, 73670, 104282, 21894, 24339, 104016, 102921, 99600, 105504, 99328, 107084, 37029, 100382, 110573, 5373, 20074, 38212, 16744, 106708, 100241, 8997, 27, 86119, 29, 28311, 30709, 30858, 111138, 99304, 101903, 3837, 37029, 100382, 110573, 102623, 113361, 101937, 3837, 77288, 102887, 100382, 110573, 104510, 104759, 104510, 1773, 104276, 73218, 23384, 100345, 26940, 100382, 110573, 24339, 25067, 99749, 116159, 105606, 3837, 100382, 61755, 107915, 104442, 104852, 100382, 110573, 103963, 20074, 62926, 23031, 102043, 101294, 57191, 99661, 104287, 102623, 100382, 110573, 100623, 1773, 91572, 3837, 100382, 110573, 104510, 104759, 104442, 26232, 106706, 100382, 61755, 107915, 57218, 100382, 110573, 103963, 20074, 18830, 72064, 9370, 100382, 65577, 1773, 100345, 26940, 100382, 110573, 24339, 25067, 99749, 117790, 105606, 3837, 104439, 57191, 104439, 106320, 99667, 112184, 75882, 24339, 104016, 102921, 99600, 105504, 99328, 107084, 37029, 100382, 110573, 5373, 20074, 38212, 16744, 106708, 100241, 3407, 100345, 104120, 114727, 3837, 30709, 30858, 100622, 99304, 101903, 96050, 102623, 39762, 91572, 80443, 101897, 100382, 110573, 104510, 104759, 104510, 1773, 100131, 3837, 100345, 100382, 110573, 24339, 105606, 3837, 101043, 104852, 100382, 110573, 103963, 20074, 62926, 23031, 102043, 101294, 57191, 99661, 104287, 102623, 100382, 110573, 100623, 101901, 114533, 100382, 61755, 107915, 1773, 101886, 3837, 30709, 30858, 73670, 106509, 100648, 100382, 110573, 20412, 104775, 3407, 103968, 3837, 111142, 85106, 100642, 101118, 1773, 62244, 101937, 100002, 100382, 110573, 9370, 104510, 18830, 112825, 90395, 101882, 30709, 30858, 67338, 104510, 110254, 103097, 88086, 102623, 3837, 100624, 73218, 23384, 73670, 106509, 101937, 107128, 1773, 100131, 3837, 62244, 101937, 80443, 112825, 100382, 110573, 9370, 104510, 101882, 3837, 100624, 30709, 30858, 9370, 100382, 110573, 73670, 115831, 88086, 3407, 99611, 17447, 113110, 3837, 30709, 30858, 73670, 106509, 100648, 100382, 110573, 20412, 104775, 3837, 106781, 101937, 112825, 34187, 100382, 110573, 9370, 104510, 101882, 1773, 99999, 3837, 30709, 30858, 73670, 101275, 78556, 114727, 3837, 57218, 73218, 23384, 71817, 105630, 104063, 33108, 105493, 3837, 104999, 101999, 100005, 102439, 1773, 18493, 100376, 74220, 17447, 3837, 62244, 105661, 101068, 100638, 3837, 42411, 73670]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "《电子签名法》第三十四条：本法中下列用语的含义：（一）电子签名人，是指持有电子签名制作数据并以本人身份或者以其所代表的人的名义实施电子签名的人；（二）电子签名依赖方，是指基于对电子签名认证证书或者电子签名的信赖从事有关活动的人；（三）电子签名认证证书，是指可证实电子签名人与电子签名制作数据有联系的数据电文或者其他电子记录；（四）电子签名制作数据，是指在电子签名过程中使用的，将电子签名与电子签名人可靠地联系起来的字符、编码等数据；（五）电子签名验证数据，是指用于验证电子签名的数据，包括代码、口令、算法或者公钥等。\n",
            "《电子签名法》第三十五条：国务院或者国务院规定的部门可以依据本法制定政务活动和其他社会活动中使用电子签名、数据电文的具体办法。\n",
            "<问题>：\n",
            "小明作为一名企业员工，使用电子签名签署了一份合同，但未经电子签名认证证书认证。此时公司方根据《电子签名法》第三十四条的规定，电子签名人是指持有电子签名制作数据并以本人身份或代表他人签署电子签名的人。同时，电子签名认证证书是指能证实电子签名人与电子签名制作数据有联系的电子记录。根据《电子签名法》第三十五条的规定，国务院或国务院规定的部门可以根据该法制定政务活动和其他社会活动中使用电子签名、数据电文的具体办法。\n",
            "\n",
            "根据上述法律规定，小明作为企业员工，在签署合同时没有经过电子签名认证证书认证。但是，根据电子签名法的规定，只有持有电子签名制作数据并以本人身份或代表他人签署电子签名的人才能被认为是电子签名人。因此，小明可以主张他的电子签名是有效的。\n",
            "\n",
            "然而，具体情况需要进一步考虑。如果合同对于电子签名的认证有明确规定，并要求小明通过认证方可视为有效签署，那么公司方可以主张合同无效。但是，如果合同没有明确规定电子签名的认证要求，那么小明的电子签名可以被视为有效。\n",
            "\n",
            "综上所述，小明可以主张他的电子签名是有效的，除非合同明确规定了电子签名的认证要求。所以，小明可以参考相关法律规定，与公司方进行合理的沟通和协商，争取维护自己的权益。在法律程序上，如果争议无法解决，他可以\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 100345, 26940, 100382, 110573, 24339, 25067, 99749, 116159, 105606, 3837, 100382, 61755, 107915, 104442, 104852, 100382, 110573, 103963, 20074, 62926, 23031, 102043, 101294, 57191, 99661, 104287, 102623, 100382, 110573, 100623, 1773, 91572, 3837, 100382, 110573, 104510, 104759, 104442, 26232, 106706, 100382, 61755, 107915, 57218, 100382, 110573, 103963, 20074, 18830, 72064, 9370, 100382, 65577, 1773, 100345, 26940, 100382, 110573, 24339, 25067, 99749, 117790, 105606, 3837, 104439, 57191, 104439, 106320, 99667, 112184, 75882, 24339, 104016, 102921, 99600, 105504, 99328, 107084, 37029, 100382, 110573, 5373, 20074, 38212, 16744, 106708, 100241, 3407, 100345, 104120, 114727, 3837, 30709, 30858, 100622, 99304, 101903, 96050, 102623, 39762, 91572, 80443, 101897, 100382, 110573, 104510, 104759, 104510, 1773, 100131, 3837, 100345, 100382, 110573, 24339, 105606, 3837, 101043, 104852, 100382, 110573, 103963, 20074, 62926, 23031, 102043, 101294, 57191, 99661, 104287, 102623, 100382, 110573, 100623, 101901, 114533, 100382, 61755, 107915, 1773, 101886, 3837, 30709, 30858, 73670, 106509, 100648, 100382, 110573, 20412, 104775, 3407, 103968, 3837, 111142, 85106, 100642, 101118, 1773, 62244, 101937, 100002, 100382, 110573, 9370, 104510, 18830, 112825, 90395, 101882, 30709, 30858, 67338, 104510, 110254, 103097, 88086, 102623, 3837, 100624, 73218, 23384, 73670, 106509, 101937, 107128, 1773, 100131, 3837, 62244, 101937, 80443, 112825, 100382, 110573, 9370, 104510, 101882, 3837, 100624, 30709, 30858, 9370, 100382, 110573, 73670, 115831, 88086, 3407, 99611, 17447, 113110, 3837, 30709, 30858, 73670, 106509, 100648, 100382, 110573, 20412, 104775, 3837, 106781, 101937, 112825, 34187, 100382, 110573, 9370, 104510, 101882, 1773, 99999, 3837, 30709, 30858, 73670, 101275, 78556, 114727, 3837, 57218, 73218, 23384, 71817, 105630, 104063, 33108, 105493, 3837, 104999, 101999, 100005, 102439, 1773, 18493, 100376, 74220, 17447, 3837, 62244, 105661, 101068, 100638, 3837, 42411, 73670]\n",
            "labels:\n",
            "根据《电子签名法》第三十四条的规定，电子签名人是指持有电子签名制作数据并以本人身份或代表他人签署电子签名的人。同时，电子签名认证证书是指能证实电子签名人与电子签名制作数据有联系的电子记录。根据《电子签名法》第三十五条的规定，国务院或国务院规定的部门可以根据该法制定政务活动和其他社会活动中使用电子签名、数据电文的具体办法。\n",
            "\n",
            "根据上述法律规定，小明作为企业员工，在签署合同时没有经过电子签名认证证书认证。但是，根据电子签名法的规定，只有持有电子签名制作数据并以本人身份或代表他人签署电子签名的人才能被认为是电子签名人。因此，小明可以主张他的电子签名是有效的。\n",
            "\n",
            "然而，具体情况需要进一步考虑。如果合同对于电子签名的认证有明确规定，并要求小明通过认证方可视为有效签署，那么公司方可以主张合同无效。但是，如果合同没有明确规定电子签名的认证要求，那么小明的电子签名可以被视为有效。\n",
            "\n",
            "综上所述，小明可以主张他的电子签名是有效的，除非合同明确规定了电子签名的认证要求。所以，小明可以参考相关法律规定，与公司方进行合理的沟通和协商，争取维护自己的权益。在法律程序上，如果争议无法解决，他可以\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 11:33:20,852 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 11:33:20,853 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|2025-04-19 11:33:20] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "[INFO|modeling_utils.py:1121] 2025-04-19 11:33:21,044 >> loading weights file /content/Qwen2.5-1.5B-Instruct/model.safetensors\n",
            "[INFO|modeling_utils.py:2167] 2025-04-19 11:33:21,045 >> Instantiating Qwen2ForCausalLM model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:1142] 2025-04-19 11:33:21,047 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "[WARNING|logging.py:328] 2025-04-19 11:33:21,059 >> Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "[INFO|modeling_utils.py:4930] 2025-04-19 11:33:33,624 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4938] 2025-04-19 11:33:33,624 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /content/Qwen2.5-1.5B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1095] 2025-04-19 11:33:33,627 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/generation_config.json\n",
            "[INFO|configuration_utils.py:1142] 2025-04-19 11:33:33,627 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n",
            "[INFO|2025-04-19 11:33:33] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-04-19 11:33:33] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-04-19 11:33:33] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-04-19 11:33:33] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-04-19 11:33:33] llamafactory.model.model_utils.misc:143 >> Found linear modules: gate_proj,down_proj,v_proj,q_proj,k_proj,up_proj,o_proj\n",
            "[INFO|2025-04-19 11:33:34] llamafactory.model.loader:143 >> trainable params: 9,232,384 || all params: 1,552,946,688 || trainable%: 0.5945\n",
            "[INFO|trainer.py:748] 2025-04-19 11:33:34,747 >> Using auto half precision backend\n",
            "[WARNING|trainer.py:783] 2025-04-19 11:33:34,747 >> No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[INFO|2025-04-19 11:33:35] llamafactory.train.trainer_utils:143 >> Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
            "[INFO|trainer.py:2414] 2025-04-19 11:33:35,209 >> ***** Running training *****\n",
            "[INFO|trainer.py:2415] 2025-04-19 11:33:35,209 >>   Num examples = 12,000\n",
            "[INFO|trainer.py:2416] 2025-04-19 11:33:35,209 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:2417] 2025-04-19 11:33:35,209 >>   Instantaneous batch size per device = 10\n",
            "[INFO|trainer.py:2420] 2025-04-19 11:33:35,209 >>   Total train batch size (w. parallel, distributed & accumulation) = 40\n",
            "[INFO|trainer.py:2421] 2025-04-19 11:33:35,209 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2422] 2025-04-19 11:33:35,209 >>   Total optimization steps = 600\n",
            "[INFO|trainer.py:2423] 2025-04-19 11:33:35,213 >>   Number of trainable parameters = 9,232,384\n",
            "{'loss': 1.1186, 'grad_norm': 0.2344837784767151, 'learning_rate': 4.9359251619630886e-05, 'epoch': 0.33}\n",
            " 17% 100/600 [25:47<2:09:52, 15.59s/it][INFO|trainer.py:3984] 2025-04-19 11:59:23,091 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-100\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 11:59:23,125 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 11:59:23,126 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 11:59:23,235 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 11:59:23,236 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-100/special_tokens_map.json\n",
            "{'loss': 0.9956, 'grad_norm': 0.26271986961364746, 'learning_rate': 4.226154222363124e-05, 'epoch': 0.67}\n",
            " 33% 200/600 [51:41<1:43:50, 15.58s/it][INFO|trainer.py:3984] 2025-04-19 12:25:16,934 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-200\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 12:25:16,967 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 12:25:16,968 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 12:25:17,068 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-200/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 12:25:17,069 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-200/special_tokens_map.json\n",
            "{'loss': 0.984, 'grad_norm': 0.22396263480186462, 'learning_rate': 2.9484364648436437e-05, 'epoch': 1.0}\n",
            " 50% 300/600 [1:17:32<1:18:04, 15.62s/it][INFO|trainer.py:3984] 2025-04-19 12:51:07,548 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-300\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 12:51:07,568 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 12:51:07,569 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 12:51:07,643 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-300/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 12:51:07,643 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-300/special_tokens_map.json\n",
            "{'loss': 0.8797, 'grad_norm': 0.24971449375152588, 'learning_rate': 1.523172178776816e-05, 'epoch': 1.33}\n",
            " 67% 400/600 [1:43:25<51:56, 15.58s/it][INFO|trainer.py:3984] 2025-04-19 13:17:00,661 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-400\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 13:17:00,681 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 13:17:00,682 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 13:17:00,757 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-400/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 13:17:00,758 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-400/special_tokens_map.json\n",
            "{'loss': 0.8554, 'grad_norm': 0.2509758770465851, 'learning_rate': 4.19308058194306e-06, 'epoch': 1.67}\n",
            " 83% 500/600 [2:09:18<26:05, 15.65s/it][INFO|trainer.py:3984] 2025-04-19 13:42:53,581 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-500\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 13:42:53,600 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 13:42:53,601 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 13:42:53,677 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 13:42:53,677 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.8535, 'grad_norm': 0.28109124302864075, 'learning_rate': 4.2307855639411865e-10, 'epoch': 2.0}\n",
            "100% 600/600 [2:35:11<00:00, 15.54s/it][INFO|trainer.py:3984] 2025-04-19 14:08:46,989 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-600\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 14:08:47,031 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 14:08:47,037 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 14:08:47,198 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-600/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 14:08:47,201 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/checkpoint-600/special_tokens_map.json\n",
            "[INFO|trainer.py:2681] 2025-04-19 14:08:48,004 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 9312.7914, 'train_samples_per_second': 2.577, 'train_steps_per_second': 0.064, 'train_loss': 0.9477825673421224, 'epoch': 2.0}\n",
            "100% 600/600 [2:35:12<00:00, 15.52s/it]\n",
            "[INFO|trainer.py:3984] 2025-04-19 14:08:48,007 >> Saving model checkpoint to /content/LLaMA-Factory/saves/qwen2.5b\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 14:08:48,045 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 14:08:48,046 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-04-19 14:08:48,202 >> tokenizer config file saved in /content/LLaMA-Factory/saves/qwen2.5b/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-04-19 14:08:48,202 >> Special tokens file saved in /content/LLaMA-Factory/saves/qwen2.5b/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  total_flos               = 90260438GF\n",
            "  train_loss               =     0.9478\n",
            "  train_runtime            = 2:35:12.79\n",
            "  train_samples_per_second =      2.577\n",
            "  train_steps_per_second   =      0.064\n",
            "Figure saved at: /content/LLaMA-Factory/saves/qwen2.5b/training_loss.png\n",
            "[WARNING|2025-04-19 14:08:48] llamafactory.extras.ploting:148 >> No metric eval_loss to plot.\n",
            "[WARNING|2025-04-19 14:08:48] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.\n",
            "[INFO|modelcard.py:450] 2025-04-19 14:08:48,794 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ],
      "source": [
        "args = dict(\n",
        "          stage=\"sft\",\n",
        "          do_train=True,\n",
        "          model_name_or_path=\"/content/Qwen2.5-1.5B-Instruct\",\n",
        "          dataset=\"law_data\",\n",
        "          template=\"qwen\",\n",
        "          finetuning_type=\"lora\",\n",
        "          lora_target=\"all\",\n",
        "          output_dir=\"/content/LLaMA-Factory/saves/qwen2.5b\",\n",
        "          cutoff_len=512,\n",
        "          per_device_train_batch_size=10,\n",
        "          gradient_accumulation_steps=4,\n",
        "          lr_scheduler_type=\"cosine\",\n",
        "          logging_steps=100,\n",
        "          warmup_ratio=0.1,\n",
        "          save_steps=100,\n",
        "          learning_rate=5e-5,\n",
        "          num_train_epochs=2,\n",
        "          max_samples=12000,  # reduce the size of train_set due to limited online GPU time\n",
        "          max_grad_norm=1.0,\n",
        "          loraplus_lr_ratio=16.0,\n",
        "          fp16=True,\n",
        "          report_to=\"none\",\n",
        "          plot_loss=True,\n",
        "          overwrite_output_dir = True,\n",
        "          )\n",
        "\n",
        "\n",
        "%cd /content/LLaMA-Factory/\n",
        "json.dump(args, open(\"train_qwen.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "!llamafactory-cli train train_qwen.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sU3f-LBDM0i"
      },
      "source": [
        "##Training Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqD8ynMuLNPI",
        "outputId": "937a0f72-426b-43a5-b499-82b13b6cabc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1186  0.9956  0.984  0.8797  0.8554  0.8535  "
          ]
        }
      ],
      "source": [
        "def read_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "# print training losses\n",
        "tl = read_jsonl(\"/content/LLaMA-Factory/saves/qwen2.5b/trainer_log.jsonl\")\n",
        "for i in tl:\n",
        "  try:\n",
        "    print(i[\"loss\"], end = \"  \")\n",
        "  except:\n",
        "    pass\n",
        "# tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "-Xg3aMksDmiq",
        "outputId": "5ce37fdb-fa85-4c50-8144-0888fd15adec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1100x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "img = mpimg.imread('/content/LLaMA-Factory/saves/qwen2.5b/training_loss.png')\n",
        "plt.figure(figsize=(11, 5))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otpDQuzaMBpm"
      },
      "source": [
        "## Inferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbFsAE-y5so4",
        "outputId": "86c4e357-ad74-4f45-95e9-82a5bffe373e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/LLaMA-Factory/src\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,799 >> loading file vocab.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,800 >> loading file merges.txt\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,802 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,803 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,804 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,805 >> loading file tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:02,805 >> loading file chat_template.jinja\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|tokenization_utils_base.py:2323] 2025-04-19 14:09:03,175 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|configuration_utils.py:691] 2025-04-19 14:09:03,176 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 14:09:03,181 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,183 >> loading file vocab.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,184 >> loading file merges.txt\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,185 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,186 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,187 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,188 >> loading file tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2058] 2025-04-19 14:09:03,189 >> loading file chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2323] 2025-04-19 14:09:03,555 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO|2025-04-19 14:09:03] llamafactory.data.template:143 >> Add <|im_end|> to stop words.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|configuration_utils.py:691] 2025-04-19 14:09:03,602 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-04-19 14:09:03,604 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO|2025-04-19 14:09:03] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|modeling_utils.py:1121] 2025-04-19 14:09:03,669 >> loading weights file /content/Qwen2.5-1.5B-Instruct/model.safetensors\n",
            "[INFO|modeling_utils.py:2167] 2025-04-19 14:09:03,671 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1142] 2025-04-19 14:09:03,675 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "[WARNING|logging.py:328] 2025-04-19 14:09:03,679 >> Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "[INFO|modeling_utils.py:4930] 2025-04-19 14:09:17,332 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4938] 2025-04-19 14:09:17,333 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /content/Qwen2.5-1.5B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1095] 2025-04-19 14:09:17,338 >> loading configuration file /content/Qwen2.5-1.5B-Instruct/generation_config.json\n",
            "[INFO|configuration_utils.py:1142] 2025-04-19 14:09:17,338 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO|2025-04-19 14:09:17] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-04-19 14:09:18] llamafactory.model.adapter:143 >> Merged 1 adapter(s).\n",
            "[INFO|2025-04-19 14:09:18] llamafactory.model.adapter:143 >> Loaded adapter(s): /content/LLaMA-Factory/saves/qwen2.5b\n",
            "[INFO|2025-04-19 14:09:18] llamafactory.model.loader:143 >> all params: 1,543,714,304\n"
          ]
        }
      ],
      "source": [
        "%cd /content/LLaMA-Factory/src\n",
        "\n",
        "from llamafactory.chat import ChatModel\n",
        "from llamafactory.extras.misc import torch_gc\n",
        "\n",
        "\n",
        "%cd /content/LLaMA-Factory\n",
        "args = dict(\n",
        "  model_name_or_path=\"/content/Qwen2.5-1.5B-Instruct\",\n",
        "  adapter_name_or_path=\"/content/LLaMA-Factory/saves/qwen2.5b\",\n",
        "  template=\"qwen\",\n",
        "  finetuning_type=\"lora\",\n",
        ")\n",
        "chat_model = ChatModel(args)\n",
        "\n",
        "# show 5 test data\n",
        "sampled_test = random.sample(test_data, 5)\n",
        "test_output = []\n",
        "\n",
        "for i in range(len(sampled_test)):\n",
        "  messages = [] #no need for history context\n",
        "\n",
        "  query = sampled_test[i][\"instruction\"]\n",
        "  messages.append({\"role\": \"user\", \"content\": query})\n",
        "  # print(\"Assistant: \", end=\"\", flush=True)\n",
        "\n",
        "  response = \"\"\n",
        "  for new_text in chat_model.stream_chat(messages):\n",
        "    # print(new_text, end=\"\", flush=True)\n",
        "    response += new_text\n",
        "  # print()\n",
        "  messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "  item = {\"question: \": query,\n",
        "          \"generated_answer: \": response,\n",
        "          \"ground_truth: \": sampled_test[i][\"output\"]}\n",
        "  # print(item)\n",
        "  test_output.append(item)\n",
        "\n",
        "torch_gc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0ki_1A6ZQHj",
        "outputId": "90ffe804-9d3d-429c-e800-27d8877d67e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| question:         | 根据案件背景，回答问题。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|                   | 案件：福建省仙游县人民检察院指控：（一）非法拘禁2015年8月25日18时许，被害人陈某以在仙游县鲤南镇仙安村“财富国际”娱乐城对面、同案人林2某（另案处理）经营的游戏机内赌博，被骗输掉人民币32000元多为由，滞留在该店附近，同案人林2某让其离开，遭到拒绝，就纠集被告人吴某、同案人林1某（已判刑）、杨某（均另案处理）等人殴打被害人陈某，并将陈某掷入一部越野车后备箱，带至仙游县鲤南镇霞苑村附近的一座山上继续殴打。直至当日19时许，同案人林2某、被告人吴某等人才将被害人陈某带至仙游县鲤南汽车站附近释放。经莆田市公安局法医学鉴定，被害人陈某的损伤程度为轻微伤。（二）容留他人吸毒2015年底间的一天、2016年3月1日左右，被告人吴某在仙游县鲤城街道“玖玖宾馆”210房间先后两次容留郑某（已行政处罚）吸食冰毒。2016年4月15日，被告人吴某在仙游县鲤城街道“天华宾馆”306房间容留刘某（已行政处罚）吸食冰毒。（三）盗窃2016年4月16日21时许，被告人吴某在仙游县鲤城街道“天下网吧”内，以打电话为由借用被害人黄某的一部玫瑰金苹果6S手机，之后以人民币3100元卖给李某。经仙游县价格认证中心价格认证，被盗玫瑰金苹果6S手机价值人民币4221元。被告人吴某于2016年4月18日被仙游县公安局抓获归案。 |\n",
            "|                   | 问题：吴某是如何偷到黄某的苹果手机？                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| generated_answer: | 根据案情描述，吴某以借用手机为由，以人民币3100元的价格将黄某的苹果手机卖给李某。因此，吴某通过欺骗手段获取了黄某的苹果手机。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| ground_truth:     | 根据案例描述分析，吴某以打电话为借口，向黄某借用了他的苹果手机，并未归还，之后将手机以较低的价格卖给了李某。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| question:         | 聂友利与北京龙鑫泰合苗木中心租赁合同纠纷一审民事判决书                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|                   | 北京市通州区人民法院                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|                   | 民 事 判 决 书                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | （2017）京0112民初38802号                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|                   | 原告：聂友利。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 委托代理人：胡才轩，北京市恒嘉律师事务所律师。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 被告：北京龙鑫泰合苗木中心，经营场所北京市通州区张家湾镇XX村北京华源发苗木花卉市场4号,统一社会信用代码×××。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|                   | 法定代表人：杜守利，经理。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|                   | 委托代理人：谭加勋，男，1987年6月21日出生，汉族，该单位职员。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|                   | 原告聂友利（以下简称原告）诉被告北京龙鑫泰合苗木中心（以下简称被告）租赁合同纠纷一案，本院于2017年XX月21日立案后，依法适用简易程序，公开开庭进行了审理。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|                   | 原告的委托代理人胡才轩，被告的委托代理人谭加勋到庭参加诉讼，本案现已审理终结。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 原告向本院提出诉讼请求：1、依法判令解除原被告之间签订的《龙鑫泰和生态园农业种植中心合作协议》；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|                   | 2、依法判令被告向原告返还租赁费165000元并支付违约金49500元，以上共计214500元；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 3、本案诉讼费由被告承担。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|                   | 事实和理由：原告与被告于2016年10月14日签订了关于原告承包租赁位于北京市通州区张家湾镇XX村“龙鑫生态园”种植大棚X排XX号的《龙鑫泰和生态园农业种植中心合作协议》。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|                   | 合同签订后，原告履行了全部义务，并按约定支付了租赁费165000元，但被告未按合同约定期限交付所租赁土地及相关租赁物。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 经查本合同约定的大棚从没建设施工，并且该项目已被拆除。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|                   | 现在本合同以没有履行的可能性，被告的违约行为已严重侵害了原告的合法权益，现原告特提起诉讼，请求法院支持原告诉求。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 被告辩称：被告履行相关义务，也已经完成大棚建设，由于政府的相关政策变化的原因，导致大棚被拆除，导致被告无法按期交付大棚，张家湾镇政府主持了协调，已经有部分承租人得到了赔偿，只有少部分承租方无法联系而没有得到赔偿，我方同意解除合同，同意返还租金，但是我方不同意支付违约金，也不同意承担诉讼费。                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|                   | 本院经审理认定事实如下：2016年10月14日，被告（甲方、出租方）与原告（乙方、承租方）签订《龙鑫泰和农业种植中心合作协议》（以下简称《合作协议》），约定：第一条，乙方承包租赁甲方开办的位于张家湾镇XX村龙鑫生态园种植大棚X排XX号，占地面积350平米。                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 第二条，第一租赁期，自2016年10月14日至2028年12月31日。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|                   | 此租赁期内，乙方按照本合同规定使用大棚。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|                   | 第二租赁期，甲方与XX村委会签订完续租合同，乙方租赁的大棚可以继续用至此合同期满，合同期限为2029年1月1日至2045年4月10日，不再另行收取日光温室大棚租赁费。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 第三条，交工日期为2017年3月31日。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|                   | 第四条，计价方式及付款方式，1、日光温室大棚租赁费为人民币165000元。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|                   | 第九条，合同的解除与终止，1、甲方如有下列行为之一的，乙方有权解除合同：（1）不能及时提供大棚或所提供的大棚不符合使用条件，严重更影响乙方正常使用的。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|                   | 第十三条，违约责任，3、单方违约导致一方要求解除合同或因单方面原因提出解除合同，导致合同解除的，违约方或提出方应按照承包总额的30%的标准向对方支付违约金。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|                   | 《合作协议》签订后原告向被告支付租金共计165000元，被告于2016年10月30日出具收据载明收到原告租金共计165000元。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|                   | 至今，被告仍未向原告交付大棚。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 上述事实，有《合作协议》、收据及当事人的陈述等证据在案佐证。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|                   | 本院认为:依法成立的合同，自成立时生效，并受法律保护。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "|                   | 当事人应当按照约定全面履行自己的义务。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|                   | 当事人一方不履行合同义务的，应当承担继续履行、采取补救措施或赔偿损失等违约责任。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 根据本案查明的事实，原告与被告签订《合作协议》系双方真实意思表示。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|                   | 原告履行了支付租金的合同义务，但被告至今仍未交付大棚，被告已构成违约。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|                   | 根据合同约定，原告据此享有解除合同，并要求被告承担违约责任的权利，现被告同意解除合同并返还租金，本院对此不持异议。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|                   | 原告主张违约金的诉讼请求，理由正当，证据充分，本院予以支持，但因被告主张违约金过高，由本院结合原告实际损失予以酌定为16500元（即按照租金总额的10%计算）。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|                   | 根据《中华人民共和国合同法》第九十四条、第六十条、第一百一十四条、《中华人民共和国民事诉讼法》第六十四条第一款之规定，判决如下：                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 一、解除原告聂友利与被告北京龙鑫泰合苗木中心于二〇一六年十月十四日签订的《龙鑫泰和农业种植中心合作协议》；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|                   | 二、被告北京龙鑫泰合苗木中心返还原告聂友利租金165000元，于本判决生效之日起七日内执行清；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|                   | 三、被告北京龙鑫泰合苗木中心支付原告聂友利违约金16500元，于判决生效之日起七日内执行清；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 四、驳回原告聂友利的其他诉讼请求。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|                   | 如果未按本判决指定的期间履行给付金钱义务，应当按照《中华人民共和国民事诉讼法》第二百五十三条之规定，加倍支付迟延履行期间的债务利息。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|                   | 案件受理费2356元，由被告北京龙鑫泰合苗木中心负担，于本判决生效之日起七日内交纳。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 如不服本判决，可在判决书送达之日起十五日内，向本院递交上诉状，并按对方当事人的人数提出副本，交纳上诉案件受理费，上诉于北京市第三中级人民法院。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 如在上诉期满后七日内未交纳上诉案件受理费的，按自动撤回上诉处理。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 审判员　　刘秉浩                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | 二〇一七年十二月十二日                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|                   | 书记员　　杨娴婷                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|                   | -4-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|                   | -1-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|                   | 请归纳这篇文书的大致要点。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| generated_answer: | 原告与被告租赁合同纠纷一案。原告提出诉求：1、依法判令解除原被告之间签订的《龙鑫泰和生态园农业种植中心合作协议》；2、依法判令被告向原告返还租赁费165000元并支付违约金49500元，以上共计214500元；3、本案诉讼费由被告承担。被告辩称：被告履行相关义务，也已经完成大棚建设，由于政府的相关政策变化的原因，导致大棚被拆除，导致被告无法按期交付大棚，张家湾镇政府主持了协调，已经有部分承租人得到了赔偿，只有少部分承租方无法联系而没有得到赔偿，我方同意解除合同，同意返还租金，但是我方不同意支付违约金，也不同意承担诉讼费。经查明：原告与被告签订的《合作协议》合法有效；被告未按约定履行交付大棚的义务，构成违约；原告要求解除合同、返还租金、支付违约金的诉讼请求，本院予以支持。 |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| ground_truth:     | 总结：原被告系租赁合同纠纷。原告提出诉讼请求：1、解除原被告之间签订的合作协议；2、被告向原告返还租赁费并支付违约金。被告辩称：我方不同意支付违约金，也不同意承担诉讼费。经审理，原告与被告签订合作协议系双方真实意思表示。现被告至今仍未交付大棚，被告已构成违约。根据合同约定，原告据此享有解除合同，并要求被告承担违约责任的权利，现被告同意解除合同并返还租金，本院对此不持异议。原告主张违约金过高，结合实际损失予以酌定给付。依照《合同法》《民事诉讼法》的规定，判决:一、解除合作协议；二、被告返还原告租金、违约金。三、驳回原告的其他诉讼请求。                                                                                                                            |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "\n",
            "+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| question:         | 资本主义法在自由资本主义时期向垄断资本主义时期的演进过程中所表现出的发展趋势，以下概括是否正确？从所有权神圣到所有权受限制。                                                                                                                                                                                                                                                     |\n",
            "|                   |                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|                   | 请先给出答案然后再给出推理过程。                                                                                                                                                                                                                                                                                                                                                 |\n",
            "+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| generated_answer: | 这个概括是正确的。在自由资本主义时期，资本主义法强调个人自由和所有权的神圣不可侵犯。然而，在垄断资本主义时期，随着资本主义经济的发展，国家开始加强对经济的干预，政府通过立法对经济活动进行规制和干预，限制私人企业的自由。这种趋势表现为从所有权神圣到所有权受限制。                                                                                                             |\n",
            "+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| ground_truth:     | 这个说法是错误的。资本主义法在自由资本主义时期向垄断资本主义时期的演进过程中，并没有表现出所有权从神圣到受限制的发展趋势。实际上，资本主义法强调私有产权的神圣性，保护个人或机构的所有权权益。尽管在垄断资本主义时期，政府和其他社会力量可能通过监管和调控来限制资本家的权力，但这并不意味着所有权的本质发生了变化。因此，资本主义法并没有从所有权神圣到所有权受限制的演进趋势。 |\n",
            "+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| question:         | 小明是一名农民，他和另一位土地经营权人小红签订了土地承包合同，约定互换土地经营权。但是，在小明将土地经营权交给小红的过程中，小红拒绝交还土地经营权。                                                                                                                                       |\n",
            "|                   |                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 小红拒不履行土地承包合同中的义务，依据相关法规，应当承担什么样的违约责任？                                                                                                                                                                                                                                                      |\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| generated_answer: | 根据《农村土地承包法》第四十六条和第四十七条的规定，小红拒绝交还土地经营权构成违约行为。根据该条款规定，如果土地经营权人小红拒绝交还土地经营权，应当承担违约责任，包括停止侵害、排除妨碍、消除危险、返还财产、恢复原状、赔偿损失等。如果给小明造成了损失，小红还应当承担损害赔偿责任。     |\n",
            "|                   |                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 根据《农村土地承包法》第四十八条的规定，如果土地承包经营权人将土地经营权互换或转让给他人，双方应当签订书面合同，并报发包方备案。同时，根据该条款规定，承包方与发包方的承包合同终止后，土地经营权的互换或转让仍然有效。                                                                     |\n",
            "|                   |                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 综上所述，小红拒不履行土地承包合同中的义务，应当承担违约责任，包括停止侵害、排除妨碍、消除危险、返还财产、恢复原状、赔偿损失等。如果给小明造成了损失，小红还应当承担损害赔偿责任。此外，根据法律规定，如果土地经营权人将土地经营权互换或转让给他人，双方应当签订书面合同，并报发包方备案。 |\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| ground_truth:     | 根据《农村土地承包法》第五十九条规定，如果一方不履行土地承包合同中的义务或者履行义务不符合约定，应当承担违约责任。                                                                                                                                                                         |\n",
            "|                   |                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 根据《农村土地承包法》第六十条规定，任何组织和个人强迫进行土地承包经营权互换、转让或者土地经营权流转的，该互换、转让或者流转无效。由此可知，小红拒绝交还土地经营权，违反了土地承包合同的约定，所进行的互换是无效的。                                                                       |\n",
            "|                   |                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 根据《农村土地承包法》第六十一条规定，任何组织和个人擅自截留、扣缴土地承包经营权互换、转让或者土地经营权流转收益的，应当退还。因此，小红应当退还小明的土地经营权。                                                                                                                         |\n",
            "|                   |                                                                                                                                                                                                                                                                                            |\n",
            "|                   | 综上所述，根据相关法规，由于小红拒不履行土地承包合同中的义务，应当承担违约责任，包括使互换无效并退还土地经营权给小明。                                                                                                                                                                     |\n",
            "+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| question:         | 《民法典》第一千一百三十一条：对继承人以外的依靠被继承人扶养的人，或者继承人以外的对被继承人扶养较多的人，可以分给适当的遗产。                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|                   | 《民法典》第一千一百三十二条：继承人应当本着互谅互让、和睦团结的精神，协商处理继承问题。遗产分割的时间、办法和份额，由继承人协商确定；协商不成的，可以由人民调解委员会调解或者向人民法院提起诉讼。                                                                                                                                                                                                                                                                                                                                 |\n",
            "|                   | 《民法典》第一千一百三十条：同一顺序继承人继承遗产的份额，一般应当均等。对生活有特殊困难又缺乏劳动能力的继承人，分配遗产时，应当予以照顾。对被继承人尽了主要扶养义务或者与被继承人共同生活的继承人，分配遗产时，可以多分。有扶养能力和有扶养条件的继承人，不尽扶养义务的，分配遗产时，应当不分或者少分。继承人协商同意的，也可以不均等。                                                                                                                                                                                           |\n",
            "|                   | <问题>：                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|                   | 李先生去世后，留下了一份价值两百万元的遗产，他的两个继承人是儿子和女儿。根据法律规定，他们应该如何分配遗产份额？是否可以不均等？                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| generated_answer: | 根据《民法典》第一千一百三十二条，继承人应当本着互谅互让、和睦团结的精神，协商处理继承问题。根据该法条，遗产分割的时间、办法和份额由继承人协商确定。如果协商不成，可以由人民调解委员会调解或者向人民法院提起诉讼。                                                                                                                                                                                                                                                                                                                 |\n",
            "|                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|                   | 根据《民法典》第一千一百三十条，同一顺序继承人继承遗产的份额，一般应当均等。如果生活有特殊困难又缺乏劳动能力的继承人，分配遗产时应当予以照顾。如果被继承人尽了主要扶养义务或者与被继承人共同生活的继承人，分配遗产时可以多分。有扶养能力和有扶养条件的继承人，不尽扶养义务的，分配遗产时应当不分或者少分。继承人协商同意的，也可以不均等。                                                                                                                                                                                         |\n",
            "|                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|                   | 综上所述，根据法律规定，李先生的两个继承人儿子和女儿可以协商确定遗产的分割方式，如果协商不成，可以由人民调解委员会调解或者向人民法院提起诉讼。至于是否可以不均等，根据法律规定，继承人应当均等分配遗产，除非存在特殊情况，如生活困难又缺乏劳动能力的继承人、被继承人尽了主要扶养义务或者与被继承人共同生活的继承人等。如果继承人协商同意，也可以不均等分配遗产。                                                                                                                                                                   |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| ground_truth:     | 根据《民法典》第一千一百三十条，同一顺序继承人继承遗产的份额一般应当均等。然而，在分配遗产时，可以考虑儿子和女儿的具体情况。例如，如果女儿生活有特殊困难且缺乏劳动能力，她可以得到更多的遗产份额以予以照顾。此外，如果儿子与被继承人共同生活或扶养被继承人的主要义务，他也可以获得较多的遗产份额。另外，继承人之间可以协商一致，决定不均等分配遗产。总之，在遵守互谅互让、和睦团结原则的前提下，儿子和女儿可以协商处理继承问题并根据具体情况决定遗产的分配份额。如果协商不成，可以通过人民调解委员会或向人民法院提起诉讼解决争议。 |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for data in test_output:\n",
        "  # data = {\"1\": \"fgdsbk\", \"2\": \"skfb\", \"3\": \"rfhb\"}\n",
        "  print(tabulate([(k, v) for k, v in data.items()],\n",
        "                tablefmt=\"grid\"))\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eERYoAOrhpcu"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login\n",
        "# import json\n",
        "\n",
        "# args = dict(\n",
        "#   model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\", # 使用非量化的官方 Llama-3-8B-Instruct 模型\n",
        "#   adapter_name_or_path=\"llama3_lora\",                       # 加载之前保存的 LoRA 适配器\n",
        "#   template=\"llama3\",                                        # 和训练保持一致\n",
        "#   finetuning_type=\"lora\",                                   # 和训练保持一致\n",
        "#   export_dir=\"llama3_lora_merged\",                          # 合并后模型的保存目录\n",
        "#   export_size=2,                                            # 合并后模型每个权重文件的大小（单位：GB）\n",
        "#   export_device=\"cpu\",                                      # 合并模型使用的设备：`cpu` 或 `auto`\n",
        "#   # export_hub_model_id=\"your_id/your_model\",               # 用于上传模型的 HuggingFace 模型 ID\n",
        "# )\n",
        "\n",
        "# json.dump(args, open(\"merge_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "# %cd /content/LLaMA-Factory/\n",
        "\n",
        "# !llamafactory-cli export merge_llama3.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
